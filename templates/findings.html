<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>University of Texas Play Caller</title>
    <!-- accessing Bootstrap content delivery network (CDN) -->
    <link
    rel="stylesheet"
    href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm"
    crossorigin="anonymous"
    />
    <!-- linking to stylesheet location, CSS -->
    <link rel="stylesheet" href="static/css/style.css">
    <link rel="icon" type="image/x-icon" href="../static/images/UTfootballLogo.jpg">
</head>

<body>
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
        <div class="container">
            <a class="navbar-brand" href="/">University of Texas Football - Defensive Play Caller</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarColor01">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarColor01">
                <ul class="navbar-nav mr-auto">
                    <li class="nav-item active">
                        <a class="nav-link" href="/">Home</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="/findings">Findings</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="/methodology">Methodology</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
    <div class="container"><br>
        <h2><b>Findings</b></h2>
        <hr>
    <div class="container">
        <div class="row">
            <h3>Model Findings</h3>
        </div>
        <div>
            <p>The UT Play Caller's goal is to predict what the opposing team would call in a given game time situation, 
                then recommend the type of defense to call for the University of Texas.  
                The data set presented dozens of features to choose from and the scaling and encoding presented even more 
                options for user input.  To make model inputs manageable for the user we ultimately chose these as the top features:</p>
            <br>
        </div>
        <div class="row">
            <h4>Feature Choices</h4>
        </div>
        <div>Evaluating the different features against the target of a <b>pass</b> or <b>rush</b> play call revealed very weak 
            correlations in all cases.  The strongest correlations were for yards gained, opponent score, down and distance.  
            Field location and UT's score had no impact.
        </div>
        <div class="row">
            <div class="col-md-4"> 
                <img src="../static/images/PlayTypeHeatMap.png" class="img-fluid" alt="Responsive image"/>
            </div>
            <div class="col-md-4" style="text-align: left"><br><br><br>
                <ul><b>Selected features included:</b><br><br>
                    <li>Half</li>
                    <li>Time Remaining</li>
                    <li>Down</li>
                    <li>Distance to go</li>
                </ul>
            </div>
            <div class="col-md-4"> <br><br>
                <img src="../static/images/feature_importance.png" width="230" height="350"/>
            </div>
            <br>
        </div>
        <div class="row"><h4>Random Forest Classifier</h4></div><br>
        <div class="row">
            <div>
                <p>We initially selected a supervised learning model to begin the machine learning algorithms.  
                    And the <b>Random Forest Classifier</b> being our first choice also turned out to be
                    the most reliable. <br><br>
                    A concern of any machine learning model is overfitting.  Borrowing from 
                    <!-- <a style="color:honeydew;" href="/findings"><b>Findings</b></a> -->
                    <a href="https://machinelearningmastery.com/overfitting-machine-learning-models/">Jason Brownlee</a>,
                    we used that visualization style to identify how deep the forest can be run before the machine learning
                    model becomes too specific to the given data set.
                </p>
            </div>
            <img src="../static/images/treeOverfit.png" class="img-fluid" alt="Responsive image"/>
            <div>
                <h6>Overfit plot. A max depth of anymore than 7 will result in overfitting.</h6><br>
            </div>
        </div>
        <div class="row"><h4>Multiple Linear Regression</h4></div><br>
        <div class="row">
            <p>By using the LinearRegression method from sklearn, and fitting the data to the model, 
               it is furthered revealed that the most impactful features are ‘quarter’, ‘down’, and ‘distance,’ 
               aligning with what we see with the correlation map detailed above.</p>
            <img src="../static/images/LinearRegressionFeatureImportance.png" class="img-fluid" alt="Responsive image"/>
        </div><br>
        <div class="row"><h4>K-Means</h4></div><br>
        <div class="row">
            <div  style="text-align: left">
            </div>
            <div style="text-align: left">
                <p>K-Means is an unsupervised learning model that attempts to identify clustering issues.   
                    In order find the optimum number of clusters for the K-Means model, we plotted
                    the clusters on the x-axis, then display the amount of data set variation on the y-axis,  
                    This variation is also referred to as inertia.  This analysis indicates that three clusters are
                    sufficient to optimize this machine learning model.<br> 
                    <img src="../static/images/kmeans_elbow_plot.png" class="img-fluid" alt="Responsive image"/>
                    <br>FYI, in the graph below, Rush is 1; pass is 0.<br>
                    <img src="../static/images/kmeans_2D_plot.png" class="img-fluid" alt="Responsive image"/>
                    <br><h6>2-D scatter plot showing pass and rush play calls.</h6>
                    <div>
                        <br>Given the plot above, it will be very difficult for this unsupervised learning model 
                        to make accurate predictions.
                        <br>Look at the 
                        <a href="/kmeans" style="color:blue;">interactive graph</a>
                        page to see one of the many data visualizations we explored to see how features correlate to the predicted play.
                    </div>
                </p>
            </div>
        </div><br>
        <div class="row "><h4>Selected model</h4></div><br>
        <div class="row">
            <p>Ultimately, we stuck with our initial choice of machine learning models, the <b>Random Forest Classifier</b>.
                <br>
                <br><b> Limitations of the model selected </b><br>
                <br>
                Though our testing and data analysis RF emerged as the optimal machine learning model for our Defensive Call Player.  
                There are a few limitations that still exist.  First, while there are options available for feature analysis when preparing the data, 
                once the model is making its decisions, it’s tough to tell what actions it’s taking. 
                The best way to counteract that is to have good data in.  Additionally, RF models aren’t as prone to overfitting as other choices,
                 meaning this model could likely be extended outside of our limited scope.
                <br>
                <br><b>Strengths of model chosen</b> <br>
                <br>
                Some features of the data showed high variance; given how a random forest (RF) machine learning model
                with many decision trees can transform this to a low variance model, we chose RF for the predictor. 
                While we’re currently looking at a relatively smaller dataset, 
                we have the ability to expand it without worrying about the model’s accuracy changing. 
                Additionally, RF models aren’t as prone to overfitting as other choices, 
                meaning this model could likely be extended outside of our limited scope. 
            </p>
        </div>
        <br>
        <div class="row "><h4>Recommendations for future development</h4></div><br>
        <div class="row">
            <p> Below are some recommendations for further development. 
                    <div>
                        <ul>
                            <li>Target data variables to account for differing opponents.  The current assumption in the model is that 
                                opponents follow Sun Tzu's philosophy and adjust formations and play calls based on opponent strength and weaknesses.</li>
                            <li>Increase predictability by removing some outliers (e.g. consecutive kneel-down plays) and assess model impact. </li>
                            <li>Incorporate a larger data set; while unseen to the user, this team has access to more than a decade of play-by-play CFB data; the current model is limited by the host site size limits.</li>
                            <li>Make the model iteratively grow; collect prediction results from user utilization to update the latest model.</li>                            
                            <li>Use a data set with formation recognition.</li>
                        </ul>
                    </div><br>
               </p>
        </div><br>
    </div>
</body>
</html>